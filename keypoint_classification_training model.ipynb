{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "igMyGnjE9hEp"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "RANDOM_SEED = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2HDvhIu9hEr"
      },
      "source": [
        "# Specify each path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "9NvZP2Zn9hEy"
      },
      "outputs": [],
      "source": [
        "dataset = 'D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint.csv'\n",
        "model_save_path = 'D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5'\n",
        "tflite_save_path = 'D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.tflite'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5oMH7x19hEz"
      },
      "source": [
        "# Set number of classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "du4kodXL9hEz"
      },
      "outputs": [],
      "source": [
        "NUM_CLASSES = 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjnL0uso9hEz"
      },
      "source": [
        "# Dataset reading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "QT5ZqtEz9hE0"
      },
      "outputs": [],
      "source": [
        "X_dataset = np.loadtxt(dataset, delimiter=',', dtype='float32', usecols=list(range(1, (21 * 2) + 1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "QmoKFsp49hE0"
      },
      "outputs": [],
      "source": [
        "y_dataset = np.loadtxt(dataset, delimiter=',', dtype='int32', usecols=(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "xQU7JTZ_9hE0"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_dataset, y_dataset, train_size=0.75, random_state=RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxK_lETT9hE0"
      },
      "source": [
        "# Model building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "vHBmUf1t9hE1"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Input((21 * 2, )),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(20, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.4),\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "    tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypqky9tc9hE1",
        "outputId": "5db082bb-30e3-4110-bf63-a1ee777ecd46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dropout_2 (Dropout)         (None, 42)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 20)                860       \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 20)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 10)                210       \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 6)                 66        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,136\n",
            "Trainable params: 1,136\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()  # tf.keras.utils.plot_model(model, show_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "MbMjOflQ9hE1"
      },
      "outputs": [],
      "source": [
        "# Model checkpoint callback\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    model_save_path, verbose=1, save_weights_only=False)\n",
        "# Callback for early stopping\n",
        "es_callback = tf.keras.callbacks.EarlyStopping(patience=20, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "c3Dac0M_9hE2"
      },
      "outputs": [],
      "source": [
        "# Model compilation\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XI0j1Iu9hE2"
      },
      "source": [
        "# Model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WirBl-JE9hE3",
        "outputId": "71b30ca2-8294-4d9d-8aa2-800d90d399de",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            " 1/12 [=>............................] - ETA: 5s - loss: 1.9943 - accuracy: 0.1328\n",
            "Epoch 1: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 1s 20ms/step - loss: 1.8773 - accuracy: 0.1596 - val_loss: 1.7099 - val_accuracy: 0.2770\n",
            "Epoch 2/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 1.8071 - accuracy: 0.2500\n",
            "Epoch 2: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.7511 - accuracy: 0.2432 - val_loss: 1.6400 - val_accuracy: 0.3951\n",
            "Epoch 3/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 1.7297 - accuracy: 0.2578\n",
            "Epoch 3: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 1.6858 - accuracy: 0.2785 - val_loss: 1.5857 - val_accuracy: 0.4440\n",
            "Epoch 4/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 1.7149 - accuracy: 0.2500\n",
            "Epoch 4: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 1.6286 - accuracy: 0.3152 - val_loss: 1.5287 - val_accuracy: 0.6008\n",
            "Epoch 5/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 1.5375 - accuracy: 0.3516\n",
            "Epoch 5: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 1.5721 - accuracy: 0.3743 - val_loss: 1.4700 - val_accuracy: 0.6497\n",
            "Epoch 6/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 1.5852 - accuracy: 0.3516\n",
            "Epoch 6: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 1.5111 - accuracy: 0.4592 - val_loss: 1.4073 - val_accuracy: 0.6701\n",
            "Epoch 7/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 1.4677 - accuracy: 0.4922\n",
            "Epoch 7: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.4550 - accuracy: 0.4755 - val_loss: 1.3417 - val_accuracy: 0.6802\n",
            "Epoch 8/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 1.4295 - accuracy: 0.4609\n",
            "Epoch 8: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.3793 - accuracy: 0.5279 - val_loss: 1.2740 - val_accuracy: 0.6823\n",
            "Epoch 9/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 1.3095 - accuracy: 0.6016\n",
            "Epoch 9: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.3453 - accuracy: 0.5312 - val_loss: 1.2036 - val_accuracy: 0.6843\n",
            "Epoch 10/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 1.2678 - accuracy: 0.5859\n",
            "Epoch 10: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.2509 - accuracy: 0.5707 - val_loss: 1.1305 - val_accuracy: 0.6823\n",
            "Epoch 11/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 1.2615 - accuracy: 0.5391\n",
            "Epoch 11: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.2262 - accuracy: 0.5625 - val_loss: 1.0623 - val_accuracy: 0.6802\n",
            "Epoch 12/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 1.2091 - accuracy: 0.5469\n",
            "Epoch 12: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.1765 - accuracy: 0.5639 - val_loss: 1.0020 - val_accuracy: 0.6843\n",
            "Epoch 13/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 1.1326 - accuracy: 0.6094\n",
            "Epoch 13: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.1202 - accuracy: 0.5808 - val_loss: 0.9514 - val_accuracy: 0.6843\n",
            "Epoch 14/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 1.2100 - accuracy: 0.5312\n",
            "Epoch 14: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.0943 - accuracy: 0.5876 - val_loss: 0.9085 - val_accuracy: 0.6843\n",
            "Epoch 15/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 1.1469 - accuracy: 0.5547\n",
            "Epoch 15: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.0560 - accuracy: 0.5774 - val_loss: 0.8729 - val_accuracy: 0.6843\n",
            "Epoch 16/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 1.0240 - accuracy: 0.6328\n",
            "Epoch 16: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.0153 - accuracy: 0.6005 - val_loss: 0.8388 - val_accuracy: 0.6904\n",
            "Epoch 17/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 1.0250 - accuracy: 0.6172\n",
            "Epoch 17: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.9784 - accuracy: 0.6155 - val_loss: 0.8060 - val_accuracy: 0.7006\n",
            "Epoch 18/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.9733 - accuracy: 0.5938\n",
            "Epoch 18: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.9554 - accuracy: 0.6209 - val_loss: 0.7760 - val_accuracy: 0.7026\n",
            "Epoch 19/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.9570 - accuracy: 0.6328\n",
            "Epoch 19: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.9295 - accuracy: 0.6365 - val_loss: 0.7474 - val_accuracy: 0.7149\n",
            "Epoch 20/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.9522 - accuracy: 0.5391\n",
            "Epoch 20: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.9243 - accuracy: 0.6196 - val_loss: 0.7214 - val_accuracy: 0.7210\n",
            "Epoch 21/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.9175 - accuracy: 0.6094\n",
            "Epoch 21: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.8828 - accuracy: 0.6420 - val_loss: 0.6971 - val_accuracy: 0.7413\n",
            "Epoch 22/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.9107 - accuracy: 0.6250\n",
            "Epoch 22: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8636 - accuracy: 0.6624 - val_loss: 0.6716 - val_accuracy: 0.7475\n",
            "Epoch 23/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.8291 - accuracy: 0.6328\n",
            "Epoch 23: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.8116 - accuracy: 0.6780 - val_loss: 0.6460 - val_accuracy: 0.7739\n",
            "Epoch 24/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.8519 - accuracy: 0.6562\n",
            "Epoch 24: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.8257 - accuracy: 0.6760 - val_loss: 0.6200 - val_accuracy: 0.7780\n",
            "Epoch 25/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.8023 - accuracy: 0.6406\n",
            "Epoch 25: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.7967 - accuracy: 0.6848 - val_loss: 0.5986 - val_accuracy: 0.7821\n",
            "Epoch 26/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.7457 - accuracy: 0.6875\n",
            "Epoch 26: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.7815 - accuracy: 0.6977 - val_loss: 0.5771 - val_accuracy: 0.7963\n",
            "Epoch 27/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.7763 - accuracy: 0.7188\n",
            "Epoch 27: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.7530 - accuracy: 0.7160 - val_loss: 0.5553 - val_accuracy: 0.8024\n",
            "Epoch 28/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.6677 - accuracy: 0.7109\n",
            "Epoch 28: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7442 - accuracy: 0.7086 - val_loss: 0.5380 - val_accuracy: 0.7963\n",
            "Epoch 29/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.6789 - accuracy: 0.7578\n",
            "Epoch 29: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.7056 - accuracy: 0.7391 - val_loss: 0.5187 - val_accuracy: 0.8106\n",
            "Epoch 30/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.7534 - accuracy: 0.7344\n",
            "Epoch 30: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.7184 - accuracy: 0.7255 - val_loss: 0.4961 - val_accuracy: 0.8330\n",
            "Epoch 31/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.7640 - accuracy: 0.7344\n",
            "Epoch 31: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.6951 - accuracy: 0.7568 - val_loss: 0.4703 - val_accuracy: 0.8798\n",
            "Epoch 32/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.6549 - accuracy: 0.7500\n",
            "Epoch 32: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.6792 - accuracy: 0.7548 - val_loss: 0.4504 - val_accuracy: 0.8819\n",
            "Epoch 33/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.6737 - accuracy: 0.7734\n",
            "Epoch 33: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.6554 - accuracy: 0.7704 - val_loss: 0.4297 - val_accuracy: 0.9022\n",
            "Epoch 34/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.6479 - accuracy: 0.7812\n",
            "Epoch 34: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.6388 - accuracy: 0.7561 - val_loss: 0.4110 - val_accuracy: 0.9124\n",
            "Epoch 35/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.6714 - accuracy: 0.8047\n",
            "Epoch 35: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6178 - accuracy: 0.7846 - val_loss: 0.3928 - val_accuracy: 0.9267\n",
            "Epoch 36/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.6515 - accuracy: 0.7578\n",
            "Epoch 36: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.6093 - accuracy: 0.7833 - val_loss: 0.3757 - val_accuracy: 0.9328\n",
            "Epoch 37/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.6450 - accuracy: 0.7734\n",
            "Epoch 37: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5936 - accuracy: 0.7853 - val_loss: 0.3558 - val_accuracy: 0.9430\n",
            "Epoch 38/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.6773 - accuracy: 0.7656\n",
            "Epoch 38: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5619 - accuracy: 0.7935 - val_loss: 0.3372 - val_accuracy: 0.9470\n",
            "Epoch 39/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.5722 - accuracy: 0.7891\n",
            "Epoch 39: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5888 - accuracy: 0.7894 - val_loss: 0.3246 - val_accuracy: 0.9470\n",
            "Epoch 40/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.5315 - accuracy: 0.8125\n",
            "Epoch 40: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5758 - accuracy: 0.7867 - val_loss: 0.3144 - val_accuracy: 0.9470\n",
            "Epoch 41/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.6140 - accuracy: 0.7891\n",
            "Epoch 41: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5654 - accuracy: 0.7955 - val_loss: 0.3047 - val_accuracy: 0.9491\n",
            "Epoch 42/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.5445 - accuracy: 0.8125\n",
            "Epoch 42: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5488 - accuracy: 0.8016 - val_loss: 0.2967 - val_accuracy: 0.9491\n",
            "Epoch 43/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.5709 - accuracy: 0.7578\n",
            "Epoch 43: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5339 - accuracy: 0.8016 - val_loss: 0.2880 - val_accuracy: 0.9491\n",
            "Epoch 44/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.6092 - accuracy: 0.7656\n",
            "Epoch 44: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5288 - accuracy: 0.8105 - val_loss: 0.2769 - val_accuracy: 0.9511\n",
            "Epoch 45/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.5320 - accuracy: 0.7656\n",
            "Epoch 45: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5433 - accuracy: 0.8084 - val_loss: 0.2672 - val_accuracy: 0.9532\n",
            "Epoch 46/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.5373 - accuracy: 0.8203\n",
            "Epoch 46: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5078 - accuracy: 0.8193 - val_loss: 0.2604 - val_accuracy: 0.9552\n",
            "Epoch 47/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.5001 - accuracy: 0.8438\n",
            "Epoch 47: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4994 - accuracy: 0.8207 - val_loss: 0.2499 - val_accuracy: 0.9552\n",
            "Epoch 48/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.5542 - accuracy: 0.8125\n",
            "Epoch 48: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4709 - accuracy: 0.8499 - val_loss: 0.2404 - val_accuracy: 0.9572\n",
            "Epoch 49/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.4923 - accuracy: 0.8359\n",
            "Epoch 49: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4607 - accuracy: 0.8505 - val_loss: 0.2305 - val_accuracy: 0.9613\n",
            "Epoch 50/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.3470 - accuracy: 0.9141\n",
            "Epoch 50: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4585 - accuracy: 0.8512 - val_loss: 0.2222 - val_accuracy: 0.9613\n",
            "Epoch 51/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.4456 - accuracy: 0.8672\n",
            "Epoch 51: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4581 - accuracy: 0.8573 - val_loss: 0.2148 - val_accuracy: 0.9593\n",
            "Epoch 52/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.5176 - accuracy: 0.8203\n",
            "Epoch 52: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4621 - accuracy: 0.8356 - val_loss: 0.2099 - val_accuracy: 0.9593\n",
            "Epoch 53/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.4792 - accuracy: 0.8516\n",
            "Epoch 53: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4709 - accuracy: 0.8410 - val_loss: 0.2055 - val_accuracy: 0.9593\n",
            "Epoch 54/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.4832 - accuracy: 0.8203\n",
            "Epoch 54: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4875 - accuracy: 0.8308 - val_loss: 0.2055 - val_accuracy: 0.9674\n",
            "Epoch 55/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.4162 - accuracy: 0.8516\n",
            "Epoch 55: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4348 - accuracy: 0.8607 - val_loss: 0.1995 - val_accuracy: 0.9674\n",
            "Epoch 56/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.4519 - accuracy: 0.8125\n",
            "Epoch 56: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4276 - accuracy: 0.8451 - val_loss: 0.1917 - val_accuracy: 0.9654\n",
            "Epoch 57/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.4312 - accuracy: 0.8594\n",
            "Epoch 57: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4303 - accuracy: 0.8560 - val_loss: 0.1838 - val_accuracy: 0.9674\n",
            "Epoch 58/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.4412 - accuracy: 0.8359\n",
            "Epoch 58: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4578 - accuracy: 0.8451 - val_loss: 0.1770 - val_accuracy: 0.9695\n",
            "Epoch 59/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.3832 - accuracy: 0.8828\n",
            "Epoch 59: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4372 - accuracy: 0.8499 - val_loss: 0.1736 - val_accuracy: 0.9695\n",
            "Epoch 60/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.4937 - accuracy: 0.8516\n",
            "Epoch 60: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4129 - accuracy: 0.8635 - val_loss: 0.1710 - val_accuracy: 0.9695\n",
            "Epoch 61/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.6256 - accuracy: 0.7812\n",
            "Epoch 61: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4247 - accuracy: 0.8567 - val_loss: 0.1684 - val_accuracy: 0.9695\n",
            "Epoch 62/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.4148 - accuracy: 0.8359\n",
            "Epoch 62: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4171 - accuracy: 0.8601 - val_loss: 0.1643 - val_accuracy: 0.9695\n",
            "Epoch 63/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.4997 - accuracy: 0.8047\n",
            "Epoch 63: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4377 - accuracy: 0.8580 - val_loss: 0.1604 - val_accuracy: 0.9674\n",
            "Epoch 64/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.3617 - accuracy: 0.8750\n",
            "Epoch 64: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4236 - accuracy: 0.8539 - val_loss: 0.1614 - val_accuracy: 0.9735\n",
            "Epoch 65/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.4347 - accuracy: 0.8047\n",
            "Epoch 65: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4235 - accuracy: 0.8526 - val_loss: 0.1603 - val_accuracy: 0.9735\n",
            "Epoch 66/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.4603 - accuracy: 0.8516\n",
            "Epoch 66: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4169 - accuracy: 0.8607 - val_loss: 0.1571 - val_accuracy: 0.9735\n",
            "Epoch 67/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.3822 - accuracy: 0.8125\n",
            "Epoch 67: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.3889 - accuracy: 0.8607 - val_loss: 0.1510 - val_accuracy: 0.9756\n",
            "Epoch 68/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.5314 - accuracy: 0.7969\n",
            "Epoch 68: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3725 - accuracy: 0.8750 - val_loss: 0.1447 - val_accuracy: 0.9756\n",
            "Epoch 69/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.3956 - accuracy: 0.8516\n",
            "Epoch 69: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4012 - accuracy: 0.8635 - val_loss: 0.1428 - val_accuracy: 0.9756\n",
            "Epoch 70/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.3380 - accuracy: 0.8984\n",
            "Epoch 70: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3747 - accuracy: 0.8784 - val_loss: 0.1418 - val_accuracy: 0.9735\n",
            "Epoch 71/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.4991 - accuracy: 0.8359\n",
            "Epoch 71: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4165 - accuracy: 0.8512 - val_loss: 0.1410 - val_accuracy: 0.9735\n",
            "Epoch 72/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.4458 - accuracy: 0.8281\n",
            "Epoch 72: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3855 - accuracy: 0.8716 - val_loss: 0.1408 - val_accuracy: 0.9756\n",
            "Epoch 73/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.4385 - accuracy: 0.8281\n",
            "Epoch 73: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.3656 - accuracy: 0.8716 - val_loss: 0.1359 - val_accuracy: 0.9776\n",
            "Epoch 74/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.4807 - accuracy: 0.8438\n",
            "Epoch 74: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.3843 - accuracy: 0.8770 - val_loss: 0.1322 - val_accuracy: 0.9735\n",
            "Epoch 75/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.3379 - accuracy: 0.8828\n",
            "Epoch 75: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3727 - accuracy: 0.8702 - val_loss: 0.1302 - val_accuracy: 0.9735\n",
            "Epoch 76/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.3769 - accuracy: 0.8828\n",
            "Epoch 76: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4134 - accuracy: 0.8499 - val_loss: 0.1313 - val_accuracy: 0.9735\n",
            "Epoch 77/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.4375 - accuracy: 0.8672\n",
            "Epoch 77: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3637 - accuracy: 0.8804 - val_loss: 0.1329 - val_accuracy: 0.9735\n",
            "Epoch 78/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.4818 - accuracy: 0.8438\n",
            "Epoch 78: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3874 - accuracy: 0.8709 - val_loss: 0.1293 - val_accuracy: 0.9756\n",
            "Epoch 79/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.4524 - accuracy: 0.8672\n",
            "Epoch 79: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.4100 - accuracy: 0.8716 - val_loss: 0.1262 - val_accuracy: 0.9756\n",
            "Epoch 80/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.3537 - accuracy: 0.8750\n",
            "Epoch 80: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.3666 - accuracy: 0.8730 - val_loss: 0.1263 - val_accuracy: 0.9756\n",
            "Epoch 81/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.4394 - accuracy: 0.8516\n",
            "Epoch 81: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.3538 - accuracy: 0.8852 - val_loss: 0.1246 - val_accuracy: 0.9756\n",
            "Epoch 82/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.4408 - accuracy: 0.8438\n",
            "Epoch 82: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.3595 - accuracy: 0.8675 - val_loss: 0.1231 - val_accuracy: 0.9756\n",
            "Epoch 83/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.3911 - accuracy: 0.8750\n",
            "Epoch 83: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.3744 - accuracy: 0.8757 - val_loss: 0.1251 - val_accuracy: 0.9735\n",
            "Epoch 84/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.4331 - accuracy: 0.8516\n",
            "Epoch 84: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3606 - accuracy: 0.8825 - val_loss: 0.1186 - val_accuracy: 0.9776\n",
            "Epoch 85/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.4419 - accuracy: 0.8203\n",
            "Epoch 85: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3646 - accuracy: 0.8764 - val_loss: 0.1149 - val_accuracy: 0.9756\n",
            "Epoch 86/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.4093 - accuracy: 0.8594\n",
            "Epoch 86: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3464 - accuracy: 0.8818 - val_loss: 0.1151 - val_accuracy: 0.9735\n",
            "Epoch 87/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.3034 - accuracy: 0.8984\n",
            "Epoch 87: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3344 - accuracy: 0.8927 - val_loss: 0.1132 - val_accuracy: 0.9735\n",
            "Epoch 88/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.3961 - accuracy: 0.8672\n",
            "Epoch 88: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.3684 - accuracy: 0.8777 - val_loss: 0.1128 - val_accuracy: 0.9715\n",
            "Epoch 89/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.3748 - accuracy: 0.9062\n",
            "Epoch 89: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3805 - accuracy: 0.8716 - val_loss: 0.1144 - val_accuracy: 0.9735\n",
            "Epoch 90/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2491 - accuracy: 0.9141\n",
            "Epoch 90: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3529 - accuracy: 0.8859 - val_loss: 0.1107 - val_accuracy: 0.9756\n",
            "Epoch 91/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.3753 - accuracy: 0.8438\n",
            "Epoch 91: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3070 - accuracy: 0.8995 - val_loss: 0.1083 - val_accuracy: 0.9735\n",
            "Epoch 92/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.3684 - accuracy: 0.8906\n",
            "Epoch 92: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3450 - accuracy: 0.8852 - val_loss: 0.1079 - val_accuracy: 0.9756\n",
            "Epoch 93/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.3895 - accuracy: 0.8594\n",
            "Epoch 93: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3628 - accuracy: 0.8825 - val_loss: 0.1040 - val_accuracy: 0.9735\n",
            "Epoch 94/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2881 - accuracy: 0.8984\n",
            "Epoch 94: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3353 - accuracy: 0.8845 - val_loss: 0.1012 - val_accuracy: 0.9756\n",
            "Epoch 95/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.3290 - accuracy: 0.9062\n",
            "Epoch 95: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3486 - accuracy: 0.8927 - val_loss: 0.1015 - val_accuracy: 0.9776\n",
            "Epoch 96/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2788 - accuracy: 0.9375\n",
            "Epoch 96: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3438 - accuracy: 0.8872 - val_loss: 0.1030 - val_accuracy: 0.9776\n",
            "Epoch 97/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2817 - accuracy: 0.9062\n",
            "Epoch 97: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3552 - accuracy: 0.8764 - val_loss: 0.1026 - val_accuracy: 0.9756\n",
            "Epoch 98/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.3156 - accuracy: 0.8906\n",
            "Epoch 98: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3387 - accuracy: 0.8954 - val_loss: 0.1036 - val_accuracy: 0.9756\n",
            "Epoch 99/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2569 - accuracy: 0.8984\n",
            "Epoch 99: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3429 - accuracy: 0.8791 - val_loss: 0.1041 - val_accuracy: 0.9756\n",
            "Epoch 100/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.4459 - accuracy: 0.8359\n",
            "Epoch 100: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3470 - accuracy: 0.8886 - val_loss: 0.1030 - val_accuracy: 0.9735\n",
            "Epoch 101/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2399 - accuracy: 0.9453\n",
            "Epoch 101: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3301 - accuracy: 0.8927 - val_loss: 0.1020 - val_accuracy: 0.9735\n",
            "Epoch 102/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.3482 - accuracy: 0.8594\n",
            "Epoch 102: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3342 - accuracy: 0.8940 - val_loss: 0.0998 - val_accuracy: 0.9735\n",
            "Epoch 103/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.3212 - accuracy: 0.8984\n",
            "Epoch 103: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3245 - accuracy: 0.8940 - val_loss: 0.0993 - val_accuracy: 0.9735\n",
            "Epoch 104/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2911 - accuracy: 0.8984\n",
            "Epoch 104: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3368 - accuracy: 0.8893 - val_loss: 0.0945 - val_accuracy: 0.9756\n",
            "Epoch 105/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.3406 - accuracy: 0.8906\n",
            "Epoch 105: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3173 - accuracy: 0.8954 - val_loss: 0.0922 - val_accuracy: 0.9756\n",
            "Epoch 106/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.3335 - accuracy: 0.8281\n",
            "Epoch 106: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3391 - accuracy: 0.8845 - val_loss: 0.0914 - val_accuracy: 0.9735\n",
            "Epoch 107/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.3934 - accuracy: 0.8516\n",
            "Epoch 107: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3011 - accuracy: 0.9001 - val_loss: 0.0904 - val_accuracy: 0.9735\n",
            "Epoch 108/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.3034 - accuracy: 0.8828\n",
            "Epoch 108: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3367 - accuracy: 0.8791 - val_loss: 0.0891 - val_accuracy: 0.9756\n",
            "Epoch 109/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2795 - accuracy: 0.9062\n",
            "Epoch 109: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3036 - accuracy: 0.9035 - val_loss: 0.0891 - val_accuracy: 0.9756\n",
            "Epoch 110/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.3570 - accuracy: 0.8750\n",
            "Epoch 110: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3310 - accuracy: 0.8865 - val_loss: 0.0881 - val_accuracy: 0.9776\n",
            "Epoch 111/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.3573 - accuracy: 0.8750\n",
            "Epoch 111: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3189 - accuracy: 0.8920 - val_loss: 0.0895 - val_accuracy: 0.9756\n",
            "Epoch 112/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2809 - accuracy: 0.9141\n",
            "Epoch 112: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3152 - accuracy: 0.8981 - val_loss: 0.0868 - val_accuracy: 0.9756\n",
            "Epoch 113/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2724 - accuracy: 0.8750\n",
            "Epoch 113: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.2904 - accuracy: 0.9022 - val_loss: 0.0881 - val_accuracy: 0.9756\n",
            "Epoch 114/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2740 - accuracy: 0.9141\n",
            "Epoch 114: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3170 - accuracy: 0.8961 - val_loss: 0.0898 - val_accuracy: 0.9756\n",
            "Epoch 115/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2916 - accuracy: 0.8984\n",
            "Epoch 115: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3081 - accuracy: 0.9049 - val_loss: 0.0879 - val_accuracy: 0.9756\n",
            "Epoch 116/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.3126 - accuracy: 0.8984\n",
            "Epoch 116: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3078 - accuracy: 0.8967 - val_loss: 0.0849 - val_accuracy: 0.9756\n",
            "Epoch 117/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.3549 - accuracy: 0.8828\n",
            "Epoch 117: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3453 - accuracy: 0.8852 - val_loss: 0.0849 - val_accuracy: 0.9756\n",
            "Epoch 118/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.3708 - accuracy: 0.9062\n",
            "Epoch 118: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3142 - accuracy: 0.9008 - val_loss: 0.0843 - val_accuracy: 0.9735\n",
            "Epoch 119/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2699 - accuracy: 0.8828\n",
            "Epoch 119: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3373 - accuracy: 0.8852 - val_loss: 0.0830 - val_accuracy: 0.9756\n",
            "Epoch 120/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.3420 - accuracy: 0.8906\n",
            "Epoch 120: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3058 - accuracy: 0.9042 - val_loss: 0.0824 - val_accuracy: 0.9756\n",
            "Epoch 121/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2205 - accuracy: 0.9453\n",
            "Epoch 121: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3051 - accuracy: 0.8981 - val_loss: 0.0825 - val_accuracy: 0.9756\n",
            "Epoch 122/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2696 - accuracy: 0.9141\n",
            "Epoch 122: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3168 - accuracy: 0.8906 - val_loss: 0.0828 - val_accuracy: 0.9756\n",
            "Epoch 123/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2011 - accuracy: 0.9531\n",
            "Epoch 123: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3214 - accuracy: 0.8859 - val_loss: 0.0834 - val_accuracy: 0.9715\n",
            "Epoch 124/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.3339 - accuracy: 0.8906\n",
            "Epoch 124: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3043 - accuracy: 0.8995 - val_loss: 0.0840 - val_accuracy: 0.9715\n",
            "Epoch 125/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2004 - accuracy: 0.9297\n",
            "Epoch 125: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3149 - accuracy: 0.8954 - val_loss: 0.0849 - val_accuracy: 0.9735\n",
            "Epoch 126/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.3832 - accuracy: 0.8750\n",
            "Epoch 126: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3239 - accuracy: 0.8981 - val_loss: 0.0844 - val_accuracy: 0.9735\n",
            "Epoch 127/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2469 - accuracy: 0.9219\n",
            "Epoch 127: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3074 - accuracy: 0.9069 - val_loss: 0.0812 - val_accuracy: 0.9756\n",
            "Epoch 128/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2588 - accuracy: 0.9141\n",
            "Epoch 128: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2907 - accuracy: 0.9090 - val_loss: 0.0785 - val_accuracy: 0.9756\n",
            "Epoch 129/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.3571 - accuracy: 0.8906\n",
            "Epoch 129: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3159 - accuracy: 0.9022 - val_loss: 0.0794 - val_accuracy: 0.9776\n",
            "Epoch 130/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2374 - accuracy: 0.9141\n",
            "Epoch 130: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2915 - accuracy: 0.8961 - val_loss: 0.0813 - val_accuracy: 0.9735\n",
            "Epoch 131/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.3440 - accuracy: 0.9062\n",
            "Epoch 131: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3030 - accuracy: 0.8988 - val_loss: 0.0825 - val_accuracy: 0.9756\n",
            "Epoch 132/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.3186 - accuracy: 0.8516\n",
            "Epoch 132: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2989 - accuracy: 0.9056 - val_loss: 0.0810 - val_accuracy: 0.9735\n",
            "Epoch 133/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2593 - accuracy: 0.9531\n",
            "Epoch 133: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2960 - accuracy: 0.9069 - val_loss: 0.0784 - val_accuracy: 0.9756\n",
            "Epoch 134/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2799 - accuracy: 0.9141\n",
            "Epoch 134: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3040 - accuracy: 0.8954 - val_loss: 0.0766 - val_accuracy: 0.9776\n",
            "Epoch 135/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.1746 - accuracy: 0.9531\n",
            "Epoch 135: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2984 - accuracy: 0.9001 - val_loss: 0.0763 - val_accuracy: 0.9756\n",
            "Epoch 136/1000\n",
            "10/12 [========================>.....] - ETA: 0s - loss: 0.2713 - accuracy: 0.9164\n",
            "Epoch 136: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.2876 - accuracy: 0.9130 - val_loss: 0.0763 - val_accuracy: 0.9756\n",
            "Epoch 137/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.3367 - accuracy: 0.8906\n",
            "Epoch 137: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2948 - accuracy: 0.9049 - val_loss: 0.0762 - val_accuracy: 0.9776\n",
            "Epoch 138/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2920 - accuracy: 0.9375\n",
            "Epoch 138: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2862 - accuracy: 0.9056 - val_loss: 0.0766 - val_accuracy: 0.9776\n",
            "Epoch 139/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.1943 - accuracy: 0.9375\n",
            "Epoch 139: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3014 - accuracy: 0.9124 - val_loss: 0.0778 - val_accuracy: 0.9756\n",
            "Epoch 140/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.3128 - accuracy: 0.8906\n",
            "Epoch 140: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3001 - accuracy: 0.8961 - val_loss: 0.0772 - val_accuracy: 0.9735\n",
            "Epoch 141/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.3869 - accuracy: 0.8750\n",
            "Epoch 141: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2935 - accuracy: 0.8961 - val_loss: 0.0760 - val_accuracy: 0.9735\n",
            "Epoch 142/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2493 - accuracy: 0.9297\n",
            "Epoch 142: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3021 - accuracy: 0.9056 - val_loss: 0.0761 - val_accuracy: 0.9756\n",
            "Epoch 143/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2520 - accuracy: 0.9219\n",
            "Epoch 143: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2827 - accuracy: 0.9062 - val_loss: 0.0754 - val_accuracy: 0.9735\n",
            "Epoch 144/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2827 - accuracy: 0.9062\n",
            "Epoch 144: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2925 - accuracy: 0.9029 - val_loss: 0.0755 - val_accuracy: 0.9756\n",
            "Epoch 145/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.3652 - accuracy: 0.8672\n",
            "Epoch 145: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2838 - accuracy: 0.9144 - val_loss: 0.0730 - val_accuracy: 0.9776\n",
            "Epoch 146/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2723 - accuracy: 0.9219\n",
            "Epoch 146: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2755 - accuracy: 0.9158 - val_loss: 0.0731 - val_accuracy: 0.9776\n",
            "Epoch 147/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2223 - accuracy: 0.8984\n",
            "Epoch 147: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2655 - accuracy: 0.9110 - val_loss: 0.0742 - val_accuracy: 0.9756\n",
            "Epoch 148/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2722 - accuracy: 0.9062\n",
            "Epoch 148: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3088 - accuracy: 0.9008 - val_loss: 0.0743 - val_accuracy: 0.9776\n",
            "Epoch 149/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.3683 - accuracy: 0.9062\n",
            "Epoch 149: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3079 - accuracy: 0.9049 - val_loss: 0.0730 - val_accuracy: 0.9756\n",
            "Epoch 150/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.1728 - accuracy: 0.9531\n",
            "Epoch 150: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2639 - accuracy: 0.9158 - val_loss: 0.0736 - val_accuracy: 0.9756\n",
            "Epoch 151/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2114 - accuracy: 0.9297\n",
            "Epoch 151: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2774 - accuracy: 0.9103 - val_loss: 0.0732 - val_accuracy: 0.9756\n",
            "Epoch 152/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.3002 - accuracy: 0.9062\n",
            "Epoch 152: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2834 - accuracy: 0.9076 - val_loss: 0.0728 - val_accuracy: 0.9776\n",
            "Epoch 153/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2591 - accuracy: 0.9219\n",
            "Epoch 153: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3029 - accuracy: 0.9035 - val_loss: 0.0723 - val_accuracy: 0.9756\n",
            "Epoch 154/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.3039 - accuracy: 0.8984\n",
            "Epoch 154: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2652 - accuracy: 0.9090 - val_loss: 0.0713 - val_accuracy: 0.9756\n",
            "Epoch 155/1000\n",
            "12/12 [==============================] - ETA: 0s - loss: 0.2635 - accuracy: 0.9158\n",
            "Epoch 155: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.2635 - accuracy: 0.9158 - val_loss: 0.0684 - val_accuracy: 0.9796\n",
            "Epoch 156/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.4244 - accuracy: 0.8438\n",
            "Epoch 156: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3111 - accuracy: 0.9056 - val_loss: 0.0699 - val_accuracy: 0.9796\n",
            "Epoch 157/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2521 - accuracy: 0.9141\n",
            "Epoch 157: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2551 - accuracy: 0.9117 - val_loss: 0.0692 - val_accuracy: 0.9796\n",
            "Epoch 158/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.3811 - accuracy: 0.8594\n",
            "Epoch 158: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2971 - accuracy: 0.8940 - val_loss: 0.0709 - val_accuracy: 0.9776\n",
            "Epoch 159/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2640 - accuracy: 0.9141\n",
            "Epoch 159: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2929 - accuracy: 0.9062 - val_loss: 0.0705 - val_accuracy: 0.9776\n",
            "Epoch 160/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.1952 - accuracy: 0.9375\n",
            "Epoch 160: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2816 - accuracy: 0.9124 - val_loss: 0.0695 - val_accuracy: 0.9776\n",
            "Epoch 161/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.4537 - accuracy: 0.8594\n",
            "Epoch 161: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2754 - accuracy: 0.9103 - val_loss: 0.0722 - val_accuracy: 0.9756\n",
            "Epoch 162/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.3026 - accuracy: 0.8750\n",
            "Epoch 162: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2713 - accuracy: 0.9035 - val_loss: 0.0730 - val_accuracy: 0.9735\n",
            "Epoch 163/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2705 - accuracy: 0.8906\n",
            "Epoch 163: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2901 - accuracy: 0.8988 - val_loss: 0.0731 - val_accuracy: 0.9735\n",
            "Epoch 164/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.3697 - accuracy: 0.8750\n",
            "Epoch 164: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2934 - accuracy: 0.9042 - val_loss: 0.0730 - val_accuracy: 0.9756\n",
            "Epoch 165/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2692 - accuracy: 0.9219\n",
            "Epoch 165: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2933 - accuracy: 0.9062 - val_loss: 0.0715 - val_accuracy: 0.9776\n",
            "Epoch 166/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.3048 - accuracy: 0.9062\n",
            "Epoch 166: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2800 - accuracy: 0.9076 - val_loss: 0.0702 - val_accuracy: 0.9776\n",
            "Epoch 167/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2276 - accuracy: 0.9062\n",
            "Epoch 167: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2911 - accuracy: 0.8961 - val_loss: 0.0689 - val_accuracy: 0.9817\n",
            "Epoch 168/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.1935 - accuracy: 0.9531\n",
            "Epoch 168: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2621 - accuracy: 0.9198 - val_loss: 0.0669 - val_accuracy: 0.9837\n",
            "Epoch 169/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.3799 - accuracy: 0.8750\n",
            "Epoch 169: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2713 - accuracy: 0.9171 - val_loss: 0.0663 - val_accuracy: 0.9796\n",
            "Epoch 170/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.1972 - accuracy: 0.9375\n",
            "Epoch 170: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2868 - accuracy: 0.9144 - val_loss: 0.0668 - val_accuracy: 0.9796\n",
            "Epoch 171/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.1995 - accuracy: 0.9141\n",
            "Epoch 171: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2983 - accuracy: 0.9035 - val_loss: 0.0672 - val_accuracy: 0.9817\n",
            "Epoch 172/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2289 - accuracy: 0.9062\n",
            "Epoch 172: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2787 - accuracy: 0.8954 - val_loss: 0.0673 - val_accuracy: 0.9796\n",
            "Epoch 173/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.3160 - accuracy: 0.8906\n",
            "Epoch 173: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2575 - accuracy: 0.9130 - val_loss: 0.0670 - val_accuracy: 0.9796\n",
            "Epoch 174/1000\n",
            "11/12 [==========================>...] - ETA: 0s - loss: 0.2595 - accuracy: 0.9134\n",
            "Epoch 174: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.2607 - accuracy: 0.9124 - val_loss: 0.0668 - val_accuracy: 0.9796\n",
            "Epoch 175/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2194 - accuracy: 0.9297\n",
            "Epoch 175: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2469 - accuracy: 0.9219 - val_loss: 0.0661 - val_accuracy: 0.9817\n",
            "Epoch 176/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2110 - accuracy: 0.9375\n",
            "Epoch 176: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2324 - accuracy: 0.9246 - val_loss: 0.0673 - val_accuracy: 0.9776\n",
            "Epoch 177/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.3213 - accuracy: 0.8672\n",
            "Epoch 177: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2559 - accuracy: 0.9110 - val_loss: 0.0669 - val_accuracy: 0.9756\n",
            "Epoch 178/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.3352 - accuracy: 0.8594\n",
            "Epoch 178: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2770 - accuracy: 0.8995 - val_loss: 0.0680 - val_accuracy: 0.9776\n",
            "Epoch 179/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.3424 - accuracy: 0.8984\n",
            "Epoch 179: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2941 - accuracy: 0.8995 - val_loss: 0.0696 - val_accuracy: 0.9756\n",
            "Epoch 180/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2490 - accuracy: 0.8906\n",
            "Epoch 180: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2765 - accuracy: 0.9008 - val_loss: 0.0678 - val_accuracy: 0.9776\n",
            "Epoch 181/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2067 - accuracy: 0.9453\n",
            "Epoch 181: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2817 - accuracy: 0.9049 - val_loss: 0.0679 - val_accuracy: 0.9776\n",
            "Epoch 182/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2517 - accuracy: 0.9141\n",
            "Epoch 182: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2575 - accuracy: 0.9192 - val_loss: 0.0685 - val_accuracy: 0.9796\n",
            "Epoch 183/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2908 - accuracy: 0.9141\n",
            "Epoch 183: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2836 - accuracy: 0.9137 - val_loss: 0.0692 - val_accuracy: 0.9756\n",
            "Epoch 184/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2800 - accuracy: 0.8906\n",
            "Epoch 184: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2914 - accuracy: 0.9015 - val_loss: 0.0678 - val_accuracy: 0.9817\n",
            "Epoch 185/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2671 - accuracy: 0.9219\n",
            "Epoch 185: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2796 - accuracy: 0.9117 - val_loss: 0.0683 - val_accuracy: 0.9796\n",
            "Epoch 186/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2082 - accuracy: 0.9531\n",
            "Epoch 186: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2513 - accuracy: 0.9246 - val_loss: 0.0703 - val_accuracy: 0.9796\n",
            "Epoch 187/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.3198 - accuracy: 0.8984\n",
            "Epoch 187: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2665 - accuracy: 0.9083 - val_loss: 0.0677 - val_accuracy: 0.9817\n",
            "Epoch 188/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2505 - accuracy: 0.8984\n",
            "Epoch 188: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2834 - accuracy: 0.8967 - val_loss: 0.0651 - val_accuracy: 0.9837\n",
            "Epoch 189/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2094 - accuracy: 0.9531\n",
            "Epoch 189: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2455 - accuracy: 0.9226 - val_loss: 0.0660 - val_accuracy: 0.9817\n",
            "Epoch 190/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.1855 - accuracy: 0.9453\n",
            "Epoch 190: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2631 - accuracy: 0.9253 - val_loss: 0.0665 - val_accuracy: 0.9817\n",
            "Epoch 191/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2461 - accuracy: 0.9219\n",
            "Epoch 191: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2600 - accuracy: 0.9164 - val_loss: 0.0653 - val_accuracy: 0.9817\n",
            "Epoch 192/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2422 - accuracy: 0.9219\n",
            "Epoch 192: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2871 - accuracy: 0.9022 - val_loss: 0.0649 - val_accuracy: 0.9817\n",
            "Epoch 193/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2199 - accuracy: 0.9219\n",
            "Epoch 193: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2625 - accuracy: 0.9164 - val_loss: 0.0631 - val_accuracy: 0.9837\n",
            "Epoch 194/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2091 - accuracy: 0.9453\n",
            "Epoch 194: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2629 - accuracy: 0.9192 - val_loss: 0.0643 - val_accuracy: 0.9796\n",
            "Epoch 195/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2379 - accuracy: 0.9375\n",
            "Epoch 195: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2557 - accuracy: 0.9185 - val_loss: 0.0657 - val_accuracy: 0.9796\n",
            "Epoch 196/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2567 - accuracy: 0.9062\n",
            "Epoch 196: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2600 - accuracy: 0.9103 - val_loss: 0.0691 - val_accuracy: 0.9796\n",
            "Epoch 197/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2162 - accuracy: 0.9141\n",
            "Epoch 197: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2657 - accuracy: 0.9171 - val_loss: 0.0678 - val_accuracy: 0.9796\n",
            "Epoch 198/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2991 - accuracy: 0.8984\n",
            "Epoch 198: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2606 - accuracy: 0.9219 - val_loss: 0.0665 - val_accuracy: 0.9796\n",
            "Epoch 199/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2805 - accuracy: 0.8828\n",
            "Epoch 199: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2589 - accuracy: 0.9171 - val_loss: 0.0632 - val_accuracy: 0.9837\n",
            "Epoch 200/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2382 - accuracy: 0.9375\n",
            "Epoch 200: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2732 - accuracy: 0.9130 - val_loss: 0.0630 - val_accuracy: 0.9837\n",
            "Epoch 201/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.1800 - accuracy: 0.9375\n",
            "Epoch 201: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2834 - accuracy: 0.9035 - val_loss: 0.0662 - val_accuracy: 0.9796\n",
            "Epoch 202/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.3214 - accuracy: 0.8672\n",
            "Epoch 202: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2579 - accuracy: 0.9151 - val_loss: 0.0664 - val_accuracy: 0.9796\n",
            "Epoch 203/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.3116 - accuracy: 0.9297\n",
            "Epoch 203: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2566 - accuracy: 0.9164 - val_loss: 0.0656 - val_accuracy: 0.9796\n",
            "Epoch 204/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2068 - accuracy: 0.9297\n",
            "Epoch 204: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2443 - accuracy: 0.9266 - val_loss: 0.0641 - val_accuracy: 0.9817\n",
            "Epoch 205/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2431 - accuracy: 0.9219\n",
            "Epoch 205: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2389 - accuracy: 0.9192 - val_loss: 0.0635 - val_accuracy: 0.9796\n",
            "Epoch 206/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.1484 - accuracy: 0.9453\n",
            "Epoch 206: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2365 - accuracy: 0.9260 - val_loss: 0.0640 - val_accuracy: 0.9796\n",
            "Epoch 207/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2582 - accuracy: 0.9375\n",
            "Epoch 207: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.2732 - accuracy: 0.9124 - val_loss: 0.0639 - val_accuracy: 0.9817\n",
            "Epoch 208/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2507 - accuracy: 0.9141\n",
            "Epoch 208: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2660 - accuracy: 0.9137 - val_loss: 0.0643 - val_accuracy: 0.9817\n",
            "Epoch 209/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.3471 - accuracy: 0.8828\n",
            "Epoch 209: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2694 - accuracy: 0.9096 - val_loss: 0.0650 - val_accuracy: 0.9817\n",
            "Epoch 210/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2831 - accuracy: 0.9141\n",
            "Epoch 210: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2505 - accuracy: 0.9185 - val_loss: 0.0679 - val_accuracy: 0.9756\n",
            "Epoch 211/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.1657 - accuracy: 0.9531\n",
            "Epoch 211: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2746 - accuracy: 0.9117 - val_loss: 0.0668 - val_accuracy: 0.9796\n",
            "Epoch 212/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2058 - accuracy: 0.9219\n",
            "Epoch 212: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2395 - accuracy: 0.9226 - val_loss: 0.0634 - val_accuracy: 0.9817\n",
            "Epoch 213/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2779 - accuracy: 0.9453\n",
            "Epoch 213: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2604 - accuracy: 0.9151 - val_loss: 0.0634 - val_accuracy: 0.9817\n",
            "Epoch 214/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.3131 - accuracy: 0.8984\n",
            "Epoch 214: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2553 - accuracy: 0.9171 - val_loss: 0.0627 - val_accuracy: 0.9796\n",
            "Epoch 215/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2655 - accuracy: 0.9141\n",
            "Epoch 215: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2383 - accuracy: 0.9198 - val_loss: 0.0611 - val_accuracy: 0.9817\n",
            "Epoch 216/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2462 - accuracy: 0.8984\n",
            "Epoch 216: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2463 - accuracy: 0.9178 - val_loss: 0.0608 - val_accuracy: 0.9817\n",
            "Epoch 217/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2495 - accuracy: 0.9062\n",
            "Epoch 217: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2568 - accuracy: 0.9137 - val_loss: 0.0618 - val_accuracy: 0.9817\n",
            "Epoch 218/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2007 - accuracy: 0.9453\n",
            "Epoch 218: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2650 - accuracy: 0.9198 - val_loss: 0.0619 - val_accuracy: 0.9817\n",
            "Epoch 219/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2603 - accuracy: 0.9062\n",
            "Epoch 219: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2405 - accuracy: 0.9205 - val_loss: 0.0610 - val_accuracy: 0.9817\n",
            "Epoch 220/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2581 - accuracy: 0.9062\n",
            "Epoch 220: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2803 - accuracy: 0.9083 - val_loss: 0.0632 - val_accuracy: 0.9817\n",
            "Epoch 221/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2761 - accuracy: 0.9219\n",
            "Epoch 221: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2743 - accuracy: 0.9130 - val_loss: 0.0652 - val_accuracy: 0.9817\n",
            "Epoch 222/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.1497 - accuracy: 0.9531\n",
            "Epoch 222: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.2431 - accuracy: 0.9158 - val_loss: 0.0651 - val_accuracy: 0.9796\n",
            "Epoch 223/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2318 - accuracy: 0.9297\n",
            "Epoch 223: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2478 - accuracy: 0.9232 - val_loss: 0.0623 - val_accuracy: 0.9817\n",
            "Epoch 224/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.1828 - accuracy: 0.9531\n",
            "Epoch 224: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2455 - accuracy: 0.9246 - val_loss: 0.0611 - val_accuracy: 0.9817\n",
            "Epoch 225/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2198 - accuracy: 0.9453\n",
            "Epoch 225: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2406 - accuracy: 0.9239 - val_loss: 0.0636 - val_accuracy: 0.9796\n",
            "Epoch 226/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.1028 - accuracy: 0.9766\n",
            "Epoch 226: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2493 - accuracy: 0.9226 - val_loss: 0.0636 - val_accuracy: 0.9817\n",
            "Epoch 227/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2607 - accuracy: 0.9062\n",
            "Epoch 227: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2485 - accuracy: 0.9158 - val_loss: 0.0629 - val_accuracy: 0.9796\n",
            "Epoch 228/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.1573 - accuracy: 0.9609\n",
            "Epoch 228: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2369 - accuracy: 0.9212 - val_loss: 0.0608 - val_accuracy: 0.9817\n",
            "Epoch 229/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2955 - accuracy: 0.9219\n",
            "Epoch 229: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2274 - accuracy: 0.9246 - val_loss: 0.0610 - val_accuracy: 0.9817\n",
            "Epoch 230/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2458 - accuracy: 0.9453\n",
            "Epoch 230: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2360 - accuracy: 0.9293 - val_loss: 0.0611 - val_accuracy: 0.9817\n",
            "Epoch 231/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.3042 - accuracy: 0.8672\n",
            "Epoch 231: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2526 - accuracy: 0.9178 - val_loss: 0.0624 - val_accuracy: 0.9796\n",
            "Epoch 232/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.3782 - accuracy: 0.8906\n",
            "Epoch 232: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2674 - accuracy: 0.9124 - val_loss: 0.0620 - val_accuracy: 0.9837\n",
            "Epoch 233/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2536 - accuracy: 0.9062\n",
            "Epoch 233: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2563 - accuracy: 0.9144 - val_loss: 0.0603 - val_accuracy: 0.9817\n",
            "Epoch 234/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2072 - accuracy: 0.9297\n",
            "Epoch 234: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2848 - accuracy: 0.9178 - val_loss: 0.0600 - val_accuracy: 0.9817\n",
            "Epoch 235/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.3534 - accuracy: 0.8672\n",
            "Epoch 235: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2325 - accuracy: 0.9300 - val_loss: 0.0585 - val_accuracy: 0.9837\n",
            "Epoch 236/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.1791 - accuracy: 0.9375\n",
            "Epoch 236: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2321 - accuracy: 0.9334 - val_loss: 0.0596 - val_accuracy: 0.9817\n",
            "Epoch 237/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2196 - accuracy: 0.9141\n",
            "Epoch 237: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.2559 - accuracy: 0.9158 - val_loss: 0.0610 - val_accuracy: 0.9817\n",
            "Epoch 238/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.1646 - accuracy: 0.9609\n",
            "Epoch 238: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2536 - accuracy: 0.9192 - val_loss: 0.0629 - val_accuracy: 0.9796\n",
            "Epoch 239/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.3332 - accuracy: 0.9141\n",
            "Epoch 239: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2683 - accuracy: 0.9164 - val_loss: 0.0606 - val_accuracy: 0.9837\n",
            "Epoch 240/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2955 - accuracy: 0.8906\n",
            "Epoch 240: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2436 - accuracy: 0.9307 - val_loss: 0.0596 - val_accuracy: 0.9817\n",
            "Epoch 241/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2380 - accuracy: 0.9219\n",
            "Epoch 241: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2454 - accuracy: 0.9280 - val_loss: 0.0604 - val_accuracy: 0.9796\n",
            "Epoch 242/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.4832 - accuracy: 0.8828\n",
            "Epoch 242: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2951 - accuracy: 0.9090 - val_loss: 0.0595 - val_accuracy: 0.9796\n",
            "Epoch 243/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.1887 - accuracy: 0.9375\n",
            "Epoch 243: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2614 - accuracy: 0.9151 - val_loss: 0.0583 - val_accuracy: 0.9817\n",
            "Epoch 244/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2921 - accuracy: 0.9062\n",
            "Epoch 244: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2516 - accuracy: 0.9219 - val_loss: 0.0599 - val_accuracy: 0.9837\n",
            "Epoch 245/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.1995 - accuracy: 0.9297\n",
            "Epoch 245: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2592 - accuracy: 0.9178 - val_loss: 0.0606 - val_accuracy: 0.9796\n",
            "Epoch 246/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.1397 - accuracy: 0.9688\n",
            "Epoch 246: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2334 - accuracy: 0.9246 - val_loss: 0.0592 - val_accuracy: 0.9817\n",
            "Epoch 247/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2785 - accuracy: 0.9141\n",
            "Epoch 247: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2532 - accuracy: 0.9158 - val_loss: 0.0580 - val_accuracy: 0.9817\n",
            "Epoch 248/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.1910 - accuracy: 0.9375\n",
            "Epoch 248: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2725 - accuracy: 0.9083 - val_loss: 0.0602 - val_accuracy: 0.9817\n",
            "Epoch 249/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2563 - accuracy: 0.9141\n",
            "Epoch 249: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2580 - accuracy: 0.9144 - val_loss: 0.0625 - val_accuracy: 0.9776\n",
            "Epoch 250/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2261 - accuracy: 0.9141\n",
            "Epoch 250: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2594 - accuracy: 0.9158 - val_loss: 0.0615 - val_accuracy: 0.9817\n",
            "Epoch 251/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2454 - accuracy: 0.9062\n",
            "Epoch 251: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.2469 - accuracy: 0.9192 - val_loss: 0.0597 - val_accuracy: 0.9837\n",
            "Epoch 252/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.1806 - accuracy: 0.9453\n",
            "Epoch 252: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2538 - accuracy: 0.9192 - val_loss: 0.0580 - val_accuracy: 0.9837\n",
            "Epoch 253/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2019 - accuracy: 0.9531\n",
            "Epoch 253: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2542 - accuracy: 0.9130 - val_loss: 0.0590 - val_accuracy: 0.9837\n",
            "Epoch 254/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.3287 - accuracy: 0.9141\n",
            "Epoch 254: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2538 - accuracy: 0.9171 - val_loss: 0.0600 - val_accuracy: 0.9837\n",
            "Epoch 255/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2891 - accuracy: 0.9062\n",
            "Epoch 255: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2362 - accuracy: 0.9219 - val_loss: 0.0625 - val_accuracy: 0.9796\n",
            "Epoch 256/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2952 - accuracy: 0.8906\n",
            "Epoch 256: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2378 - accuracy: 0.9232 - val_loss: 0.0632 - val_accuracy: 0.9817\n",
            "Epoch 257/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.3842 - accuracy: 0.9297\n",
            "Epoch 257: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2698 - accuracy: 0.9171 - val_loss: 0.0612 - val_accuracy: 0.9817\n",
            "Epoch 258/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.1963 - accuracy: 0.9297\n",
            "Epoch 258: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2460 - accuracy: 0.9151 - val_loss: 0.0608 - val_accuracy: 0.9817\n",
            "Epoch 259/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.3134 - accuracy: 0.9141\n",
            "Epoch 259: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2496 - accuracy: 0.9212 - val_loss: 0.0589 - val_accuracy: 0.9837\n",
            "Epoch 260/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2832 - accuracy: 0.8906\n",
            "Epoch 260: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2635 - accuracy: 0.9124 - val_loss: 0.0585 - val_accuracy: 0.9837\n",
            "Epoch 261/1000\n",
            "12/12 [==============================] - ETA: 0s - loss: 0.2417 - accuracy: 0.9260\n",
            "Epoch 261: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.2417 - accuracy: 0.9260 - val_loss: 0.0605 - val_accuracy: 0.9817\n",
            "Epoch 262/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.1620 - accuracy: 0.9609\n",
            "Epoch 262: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2394 - accuracy: 0.9341 - val_loss: 0.0597 - val_accuracy: 0.9817\n",
            "Epoch 263/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2606 - accuracy: 0.9297\n",
            "Epoch 263: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2423 - accuracy: 0.9253 - val_loss: 0.0573 - val_accuracy: 0.9817\n",
            "Epoch 264/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2339 - accuracy: 0.9531\n",
            "Epoch 264: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2393 - accuracy: 0.9246 - val_loss: 0.0569 - val_accuracy: 0.9817\n",
            "Epoch 265/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2379 - accuracy: 0.9297\n",
            "Epoch 265: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2380 - accuracy: 0.9260 - val_loss: 0.0583 - val_accuracy: 0.9796\n",
            "Epoch 266/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2066 - accuracy: 0.9297\n",
            "Epoch 266: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2587 - accuracy: 0.9151 - val_loss: 0.0578 - val_accuracy: 0.9837\n",
            "Epoch 267/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2545 - accuracy: 0.8984\n",
            "Epoch 267: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2374 - accuracy: 0.9164 - val_loss: 0.0574 - val_accuracy: 0.9837\n",
            "Epoch 268/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.1617 - accuracy: 0.9766\n",
            "Epoch 268: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2290 - accuracy: 0.9293 - val_loss: 0.0603 - val_accuracy: 0.9837\n",
            "Epoch 269/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.1695 - accuracy: 0.9453\n",
            "Epoch 269: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2253 - accuracy: 0.9246 - val_loss: 0.0588 - val_accuracy: 0.9837\n",
            "Epoch 270/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2290 - accuracy: 0.9062\n",
            "Epoch 270: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.2458 - accuracy: 0.9171 - val_loss: 0.0580 - val_accuracy: 0.9837\n",
            "Epoch 271/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.1827 - accuracy: 0.9453\n",
            "Epoch 271: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2497 - accuracy: 0.9124 - val_loss: 0.0585 - val_accuracy: 0.9817\n",
            "Epoch 272/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2130 - accuracy: 0.9375\n",
            "Epoch 272: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2262 - accuracy: 0.9287 - val_loss: 0.0589 - val_accuracy: 0.9817\n",
            "Epoch 273/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.1931 - accuracy: 0.9375\n",
            "Epoch 273: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2340 - accuracy: 0.9334 - val_loss: 0.0598 - val_accuracy: 0.9817\n",
            "Epoch 274/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.1694 - accuracy: 0.9531\n",
            "Epoch 274: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2623 - accuracy: 0.9137 - val_loss: 0.0592 - val_accuracy: 0.9817\n",
            "Epoch 275/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2224 - accuracy: 0.9219\n",
            "Epoch 275: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2556 - accuracy: 0.9130 - val_loss: 0.0595 - val_accuracy: 0.9837\n",
            "Epoch 276/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2849 - accuracy: 0.9141\n",
            "Epoch 276: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2309 - accuracy: 0.9171 - val_loss: 0.0588 - val_accuracy: 0.9837\n",
            "Epoch 277/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2088 - accuracy: 0.9531\n",
            "Epoch 277: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2322 - accuracy: 0.9246 - val_loss: 0.0607 - val_accuracy: 0.9837\n",
            "Epoch 278/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2067 - accuracy: 0.9375\n",
            "Epoch 278: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2201 - accuracy: 0.9260 - val_loss: 0.0620 - val_accuracy: 0.9796\n",
            "Epoch 279/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.3873 - accuracy: 0.9219\n",
            "Epoch 279: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2700 - accuracy: 0.9212 - val_loss: 0.0607 - val_accuracy: 0.9796\n",
            "Epoch 280/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2820 - accuracy: 0.9062\n",
            "Epoch 280: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2424 - accuracy: 0.9226 - val_loss: 0.0595 - val_accuracy: 0.9796\n",
            "Epoch 281/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.1618 - accuracy: 0.9375\n",
            "Epoch 281: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.2345 - accuracy: 0.9293 - val_loss: 0.0593 - val_accuracy: 0.9796\n",
            "Epoch 282/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2412 - accuracy: 0.9297\n",
            "Epoch 282: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2245 - accuracy: 0.9280 - val_loss: 0.0577 - val_accuracy: 0.9817\n",
            "Epoch 283/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.2158 - accuracy: 0.9375\n",
            "Epoch 283: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2222 - accuracy: 0.9293 - val_loss: 0.0570 - val_accuracy: 0.9817\n",
            "Epoch 284/1000\n",
            " 1/12 [=>............................] - ETA: 0s - loss: 0.3559 - accuracy: 0.8984\n",
            "Epoch 284: saving model to D:\\VS_CODE_WORKSPACE\\python\\ML\\hand-gesture-recognition-mediapipe-main\\model\\keypoint_classifier\\keypoint_classifier.hdf5\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2618 - accuracy: 0.9110 - val_loss: 0.0570 - val_accuracy: 0.9817\n",
            "Epoch 284: early stopping\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x253f32afed0>"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=1000,\n",
        "    batch_size=128,\n",
        "    validation_data=(X_test, y_test),\n",
        "    callbacks=[cp_callback, es_callback]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxvb2Y299hE3",
        "outputId": "59eb3185-2e37-4b9e-bc9d-ab1b8ac29b7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0570 - accuracy: 0.9817\n"
          ]
        }
      ],
      "source": [
        "# Model evaluation\n",
        "val_loss, val_acc = model.evaluate(X_test, y_test, batch_size=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "RBkmDeUW9hE4"
      },
      "outputs": [],
      "source": [
        "# Loading the saved model\n",
        "model = tf.keras.models.load_model(model_save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFz9Tb0I9hE4",
        "outputId": "1c3b3528-54ae-4ee2-ab04-77429211cbef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 48ms/step\n",
            "[9.9506439e-04 1.5803881e-04 9.7992194e-01 7.7813644e-07 7.2949217e-07\n",
            " 1.8923404e-02]\n",
            "2\n"
          ]
        }
      ],
      "source": [
        "# Inference test\n",
        "predict_result = model.predict(np.array([X_test[0]]))\n",
        "print(np.squeeze(predict_result))\n",
        "print(np.argmax(np.squeeze(predict_result)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3U4yNWx9hE4"
      },
      "source": [
        "# Confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "AP1V6SCk9hE5",
        "outputId": "08e41a80-7a4a-4619-8125-ecc371368d19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16/16 [==============================] - 0s 1ms/step\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 700x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98       132\n",
            "           1       1.00      1.00      1.00        92\n",
            "           2       0.98      1.00      0.99        43\n",
            "           3       0.95      1.00      0.97        56\n",
            "           4       1.00      1.00      1.00        73\n",
            "           5       0.99      0.92      0.95        95\n",
            "\n",
            "    accuracy                           0.98       491\n",
            "   macro avg       0.98      0.98      0.98       491\n",
            "weighted avg       0.98      0.98      0.98       491\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "def print_confusion_matrix(y_true, y_pred, report=True):\n",
        "    labels = sorted(list(set(y_true)))\n",
        "    cmx_data = confusion_matrix(y_true, y_pred, labels=labels)\n",
        "    \n",
        "    df_cmx = pd.DataFrame(cmx_data, index=labels, columns=labels)\n",
        " \n",
        "    fig, ax = plt.subplots(figsize=(7, 6))\n",
        "    sns.heatmap(df_cmx, annot=True, fmt='g' ,square=False)\n",
        "    ax.set_ylim(len(set(y_true)), 0)\n",
        "    plt.show()\n",
        "    \n",
        "    if report:\n",
        "        print('Classification Report')\n",
        "        print(classification_report(y_test, y_pred))\n",
        "\n",
        "Y_pred = model.predict(X_test)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "\n",
        "print_confusion_matrix(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNP6aqzc9hE5"
      },
      "source": [
        "# Convert to model for Tensorflow-Lite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "ODjnYyld9hE6"
      },
      "outputs": [],
      "source": [
        "# Save as a model dedicated to inference\n",
        "model.save(model_save_path, include_optimizer=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRfuK8Y59hE6",
        "outputId": "a4ca585c-b5d5-4244-8291-8674063209bb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "6552"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Transform model (quantization)\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_quantized_model = converter.convert()\n",
        "\n",
        "open(tflite_save_path, 'wb').write(tflite_quantized_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHBPBXdx9hE6"
      },
      "source": [
        "# Inference test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "mGAzLocO9hE7"
      },
      "outputs": [],
      "source": [
        "interpreter = tf.lite.Interpreter(model_path=tflite_save_path)\n",
        "interpreter.allocate_tensors()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "oQuDK8YS9hE7"
      },
      "outputs": [],
      "source": [
        "# Get I / O tensor\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "2_ixAf_l9hE7"
      },
      "outputs": [],
      "source": [
        "interpreter.set_tensor(input_details[0]['index'], np.array([X_test[0]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4FoAnuc9hE7",
        "outputId": "91f18257-8d8b-4ef3-c558-e9b5f94fabbf",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: total: 0 ns\n",
            "Wall time: 0 ns\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Inference implementation\n",
        "interpreter.invoke()\n",
        "tflite_results = interpreter.get_tensor(output_details[0]['index'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vONjp19J9hE8",
        "outputId": "77205e24-fd00-42c4-f7b6-e06e527c2cba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[9.9506252e-04 1.5803854e-04 9.7992206e-01 7.7813428e-07 7.2948950e-07\n",
            " 1.8923391e-02]\n",
            "2\n"
          ]
        }
      ],
      "source": [
        "print(np.squeeze(tflite_results))\n",
        "print(np.argmax(np.squeeze(tflite_results)))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "keypoint_classification_EN.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
